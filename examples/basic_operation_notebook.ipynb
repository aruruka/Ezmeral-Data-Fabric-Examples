{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup S3 Environment\n",
    "Import required libraries and set up logging configurations. Configure AWS credentials and region for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import logging\n",
    "import boto3\n",
    "from botocore.exceptions import NoCredentialsError, PartialCredentialsError\n",
    "\n",
    "# Set up logging configurations\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# Configure AWS credentials and region for testing\n",
    "aws_access_key_id = 'YOUR_ACCESS_KEY_ID'\n",
    "aws_secret_access_key = 'YOUR_SECRET_ACCESS_KEY'\n",
    "aws_region = 'YOUR_AWS_REGION'\n",
    "\n",
    "# Initialize the S3 client\n",
    "try:\n",
    "    s3_client = boto3.client(\n",
    "        's3',\n",
    "        aws_access_key_id=aws_access_key_id,\n",
    "        aws_secret_access_key=aws_secret_access_key,\n",
    "        region_name=aws_region\n",
    "    )\n",
    "    logger.info(\"S3 client initialized successfully.\")\n",
    "except (NoCredentialsError, PartialCredentialsError) as e:\n",
    "    logger.error(\"AWS credentials not found or incomplete. Please check your configuration.\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize S3 Client and Managers\n",
    "Create S3Client instance and initialize BucketManager and ObjectManager with debug output for connection verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries for S3 operations\n",
    "from s3_operations.s3_client import S3Client\n",
    "from s3_operations.bucket_manager import BucketManager\n",
    "from s3_operations.object_manager import ObjectManager\n",
    "\n",
    "# Initialize S3Client instance\n",
    "s3_client_instance = S3Client().get_client()\n",
    "\n",
    "# Initialize BucketManager and ObjectManager with the S3 client\n",
    "bucket_manager = BucketManager(s3_client_instance)\n",
    "object_manager = ObjectManager(s3_client_instance)\n",
    "\n",
    "# Debug output to verify connection\n",
    "try:\n",
    "    # List buckets to verify connection\n",
    "    buckets = s3_client_instance.list_buckets()\n",
    "    logger.info(\"S3 connection verified. Buckets available: %s\", [bucket['Name'] for bucket in buckets['Buckets']])\n",
    "except Exception as e:\n",
    "    logger.error(\"Failed to verify S3 connection: %s\", e)\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bucket Operations\n",
    "Test bucket creation with unique names. Add debugging statements to verify bucket existence and creation status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Function to create a unique bucket name\n",
    "def create_unique_bucket_name(base_name):\n",
    "    return f\"{base_name}-{datetime.now().strftime('%Y%m%d%H%M%S')}\"\n",
    "\n",
    "# Create a unique bucket name\n",
    "test_bucket_name = create_unique_bucket_name(\"test-bucket\")\n",
    "logger.info(\"Generated unique bucket name: %s\", test_bucket_name)\n",
    "\n",
    "# Attempt to create the bucket\n",
    "bucket_created = bucket_manager.create_bucket(test_bucket_name)\n",
    "if bucket_created:\n",
    "    logger.info(\"Bucket '%s' created successfully.\", test_bucket_name)\n",
    "else:\n",
    "    logger.error(\"Failed to create bucket '%s'.\", test_bucket_name)\n",
    "\n",
    "# Verify bucket existence\n",
    "bucket_exists = bucket_manager.check_bucket_exists(test_bucket_name)\n",
    "if bucket_exists:\n",
    "    logger.info(\"Bucket '%s' exists.\", test_bucket_name)\n",
    "else:\n",
    "    logger.error(\"Bucket '%s' does not exist.\", test_bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Upload and Download\n",
    "Create test files, upload them to S3, and verify the upload process. Include progress tracking and file integrity checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object Upload and Download\n",
    "\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "# Create a temporary test file\n",
    "with tempfile.NamedTemporaryFile(delete=False) as tmp_file:\n",
    "    tmp_file.write(b\"Test content for S3 upload\")\n",
    "    tmp_path = tmp_file.name\n",
    "\n",
    "logger.info(\"Temporary test file created at: %s\", tmp_path)\n",
    "\n",
    "# Upload the test file to the S3 bucket\n",
    "upload_success = object_manager.upload_file(test_bucket_name, tmp_path, \"test-file.txt\")\n",
    "if upload_success:\n",
    "    logger.info(\"File uploaded successfully to bucket '%s' as 'test-file.txt'.\", test_bucket_name)\n",
    "else:\n",
    "    logger.error(\"Failed to upload file to bucket '%s'.\", test_bucket_name)\n",
    "\n",
    "# List objects in the bucket to verify upload\n",
    "logger.info(\"Listing objects in bucket '%s':\", test_bucket_name)\n",
    "for page in object_manager.list_objects_paginated(test_bucket_name):\n",
    "    for obj in page:\n",
    "        logger.info(\" - %s\", obj)\n",
    "\n",
    "# Download the uploaded file\n",
    "download_path = \"/tmp/downloaded_test_file.txt\"\n",
    "download_success = object_manager.download_file(test_bucket_name, \"test-file.txt\", download_path)\n",
    "if download_success:\n",
    "    logger.info(\"File downloaded successfully from bucket '%s' to '%s'.\", test_bucket_name, download_path)\n",
    "else:\n",
    "    logger.error(\"Failed to download file from bucket '%s'.\", test_bucket_name)\n",
    "\n",
    "# Verify file integrity by comparing content\n",
    "with open(download_path, 'rb') as downloaded_file:\n",
    "    downloaded_content = downloaded_file.read()\n",
    "\n",
    "with open(tmp_path, 'rb') as original_file:\n",
    "    original_content = original_file.read()\n",
    "\n",
    "if downloaded_content == original_content:\n",
    "    logger.info(\"File integrity check passed. The downloaded file matches the original file.\")\n",
    "else:\n",
    "    logger.error(\"File integrity check failed. The downloaded file does not match the original file.\")\n",
    "\n",
    "# Clean up temporary files\n",
    "os.remove(tmp_path)\n",
    "os.remove(download_path)\n",
    "logger.info(\"Temporary files cleaned up.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List and Paginate Objects\n",
    "Demonstrate object listing with pagination, including detailed inspection of object metadata and debug outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List and Paginate Objects\n",
    "\n",
    "# List objects in the bucket with pagination and detailed inspection\n",
    "logger.info(\"Listing objects in bucket '%s' with pagination and detailed inspection:\", test_bucket_name)\n",
    "for page in object_manager.list_objects_paginated(test_bucket_name):\n",
    "    for obj in page:\n",
    "        logger.info(\"Object Key: %s\", obj['Key'])\n",
    "        logger.info(\" - Last Modified: %s\", obj['LastModified'])\n",
    "        logger.info(\" - Size: %d\", obj['Size'])\n",
    "        logger.info(\" - Storage Class: %s\", obj['StorageClass'])\n",
    "        logger.info(\" - ETag: %s\", obj['ETag'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Handling and Debugging\n",
    "Test various error scenarios and add exception handling with detailed error messages and stack traces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error Handling and Debugging\n",
    "\n",
    "import traceback\n",
    "\n",
    "# Test error scenario: Attempt to create a bucket with an invalid name\n",
    "invalid_bucket_name = \"Invalid_Bucket_Name_With_Uppercase\"\n",
    "try:\n",
    "    bucket_manager.create_bucket(invalid_bucket_name)\n",
    "except Exception as e:\n",
    "    logger.error(\"Error creating bucket with invalid name '%s': %s\", invalid_bucket_name, e)\n",
    "    logger.debug(\"Stack trace:\\n%s\", traceback.format_exc())\n",
    "\n",
    "# Test error scenario: Attempt to upload a file to a non-existent bucket\n",
    "non_existent_bucket = \"non-existent-bucket\"\n",
    "try:\n",
    "    object_manager.upload_file(non_existent_bucket, tmp_path, \"test-file.txt\")\n",
    "except Exception as e:\n",
    "    logger.error(\"Error uploading file to non-existent bucket '%s': %s\", non_existent_bucket, e)\n",
    "    logger.debug(\"Stack trace:\\n%s\", traceback.format_exc())\n",
    "\n",
    "# Test error scenario: Attempt to download a non-existent file\n",
    "try:\n",
    "    object_manager.download_file(test_bucket_name, \"non-existent-file.txt\", download_path)\n",
    "except Exception as e:\n",
    "    logger.error(\"Error downloading non-existent file from bucket '%s': %s\", test_bucket_name, e)\n",
    "    logger.debug(\"Stack trace:\\n%s\", traceback.format_exc())\n",
    "\n",
    "# Test error scenario: Attempt to delete a non-existent bucket\n",
    "try:\n",
    "    bucket_manager.delete_bucket(non_existent_bucket)\n",
    "except Exception as e:\n",
    "    logger.error(\"Error deleting non-existent bucket '%s': %s\", non_existent_bucket, e)\n",
    "    logger.debug(\"Stack trace:\\n%s\", traceback.format_exc())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleanup Operations\n",
    "Implement and verify cleanup procedures for test files and buckets with confirmation checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup Operations\n",
    "\n",
    "# Delete the uploaded test file from the S3 bucket\n",
    "delete_success = object_manager.delete_file(test_bucket_name, \"test-file.txt\")\n",
    "if delete_success:\n",
    "    logger.info(\"File 'test-file.txt' deleted successfully from bucket '%s'.\", test_bucket_name)\n",
    "else:\n",
    "    logger.error(\"Failed to delete file 'test-file.txt' from bucket '%s'.\", test_bucket_name)\n",
    "\n",
    "# Verify the file deletion by listing objects again\n",
    "logger.info(\"Verifying file deletion by listing objects in bucket '%s':\", test_bucket_name)\n",
    "for page in object_manager.list_objects_paginated(test_bucket_name):\n",
    "    for obj in page:\n",
    "        logger.info(\" - %s\", obj)\n",
    "\n",
    "# Delete the test bucket\n",
    "bucket_delete_success = bucket_manager.delete_bucket(test_bucket_name)\n",
    "if bucket_delete_success:\n",
    "    logger.info(\"Bucket '%s' deleted successfully.\", test_bucket_name)\n",
    "else:\n",
    "    logger.error(\"Failed to delete bucket '%s'.\", test_bucket_name)\n",
    "\n",
    "# Verify the bucket deletion\n",
    "bucket_exists = bucket_manager.check_bucket_exists(test_bucket_name)\n",
    "if not bucket_exists:\n",
    "    logger.info(\"Bucket '%s' confirmed deleted.\", test_bucket_name)\n",
    "else:\n",
    "    logger.error(\"Bucket '%s' still exists after deletion attempt.\", test_bucket_name)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
